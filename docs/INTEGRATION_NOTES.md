# Trieve Integration Notes for cloud-pipeline-handler

This document provides specific guidance for integrating Trieve with the cloud-pipeline-handler RAG system.

## Table of Contents

- [Overview](#overview)
- [Data Model Mapping](#data-model-mapping)
- [API Implementation Verification](#api-implementation-verification)
- [Configuration Guide](#configuration-guide)
- [Performance Considerations](#performance-considerations)
- [Scaling Recommendations](#scaling-recommendations)
- [Comparison with AnythingLLM](#comparison-with-anythingllm)
- [Migration Considerations](#migration-considerations)
- [Testing Strategy](#testing-strategy)

## Overview

Your cloud-pipeline-handler application implements a swappable RAG provider architecture. This document verifies that your Trieve implementation (`src/rag/trieve.rs`) correctly uses the Trieve API and provides optimization guidance.

### Your Architecture

```
cloud-pipeline-handler
‚îú‚îÄ‚îÄ src/rag/
‚îÇ   ‚îú‚îÄ‚îÄ provider.rs       # RAG provider trait
‚îÇ   ‚îú‚îÄ‚îÄ trieve.rs         # Trieve implementation ‚úì
‚îÇ   ‚îú‚îÄ‚îÄ anythingllm.rs    # AnythingLLM implementation
‚îÇ   ‚îî‚îÄ‚îÄ mod.rs            # Provider factory
‚îú‚îÄ‚îÄ src/config/mod.rs     # Configuration
‚îî‚îÄ‚îÄ migrations/
    ‚îî‚îÄ‚îÄ 012_add_device_isolation_to_rag.sql
```

### Use Case

**Industrial Equipment Maintenance with Edge AI**

```
Edge Device (Pump-001)
    ‚Üì Sensor Data
Cloud Pipeline Handler
    ‚Üì AI Analysis
RAG Provider (Trieve)
    ‚Üì Query: "How to fix pressure drop?"
Pump-001 Manual Dataset
    ‚Üì Relevant Chunks
AI Response: "Based on manual, check seals..."
```

## Data Model Mapping

### Your Model ‚Üí Trieve Model

| Your Concept | Trieve Concept | Implementation |
|--------------|----------------|----------------|
| Organization (`org_id`) | Trieve Organization | One per customer or shared |
| Device (`device_id`) | Trieve Dataset | `org-{uuid}-device-{device_id}` |
| Equipment Manual (PDF) | Trieve File | Uploaded with base64 encoding |
| Manual Sections | Trieve Chunks | Auto-created from files |
| Search Query | Trieve Search | Semantic/Hybrid search |

### Dataset Naming Convention

**Your Implementation:**
```rust
format!("org-{}-device-{}", org_id, device_id)
```

**Recommendation:** ‚úì This is correct and follows best practices.

**Examples:**
```
org-123e4567-e89b-12d3-a456-426614174000-device-pump-001
org-123e4567-e89b-12d3-a456-426614174000-device-compressor-002
org-987f6543-e21c-45d8-b123-987654321000-device-hvac-001
```

**Benefits:**
- Clear hierarchical structure
- Easy to identify organization and device from dataset name
- Prevents naming conflicts
- Enables easy filtering and management

### Alternative: Use Tracking IDs

You can also use `tracking_id` for cleaner lookups:

```rust
// Create dataset with tracking_id
CreateDatasetRequest {
    dataset_name: format!("org-{}-device-{}", org_id, device_id),
    tracking_id: Some(device_id.clone()),  // Just the device_id
    // ...
}

// Later, query using tracking_id
let dataset = get_dataset_by_tracking_id(device_id).await?;
```

**Benefits:**
- Simpler queries (use device_id directly)
- No need to store dataset UUIDs
- More intuitive API usage

## API Implementation Verification

Based on Trieve's actual API (reviewed from source code), here's verification of your implementation:

### ‚úÖ Dataset Creation

**Your Implementation:**
```rust
POST /api/dataset
Headers:
  - Authorization: Bearer {API_KEY}
  - TR-Organization: {ORG_ID}
Body: {
  "dataset_name": "org-{uuid}-device-{device_id}",
  "server_configuration": {
    "FULLTEXT_ENABLED": true
  }
}
```

**Verdict:** ‚úÖ **CORRECT**

**Recommendations:**
1. Add `tracking_id` field:
   ```json
   {
     "dataset_name": "org-...-device-pump-001",
     "tracking_id": "device-pump-001",
     "server_configuration": { ... }
   }
   ```

2. Recommended server_configuration:
   ```json
   {
     "FULLTEXT_ENABLED": true,
     "SEMANTIC_ENABLED": true,
     "BM25_ENABLED": true,
     "EMBEDDING_SIZE": 1536,
     "DISTANCE_METRIC": "cosine"
   }
   ```

### ‚úÖ File Upload

**Your Implementation:**
```rust
POST /api/file
Headers:
  - Authorization: Bearer {API_KEY}
  - TR-Dataset: {DATASET_ID}
Body: {
  "base64_file": "{base64_encoded_pdf}",
  "file_name": "equipment-manual.pdf",
  "create_chunks": true,
  "description": "Equipment manual for device: ...",
  "tag_set": ["device:pump-001"]
}
```

**Verdict:** ‚úÖ **CORRECT** with minor notes

**Notes:**

1. **`create_chunks` field**: This field doesn't exist in the actual API. Remove it.
   - Chunks are **always** created automatically for file uploads
   - No parameter needed

2. **Base64 encoding**: ‚úÖ Standard base64 is accepted
   - Server handles both standard and base64url formats
   - Your Rust implementation can use `base64::encode()` directly

3. **Recommended fields**:
   ```json
   {
     "base64_file": "...",
     "file_name": "pump-manual.pdf",
     "tag_set": ["device:pump-001", "manual", "maintenance"],
     "description": "Maintenance manual for pump-001",
     "metadata": {
       "device_id": "pump-001",
       "equipment_type": "pump",
       "uploaded_at": "2024-01-01T00:00:00Z"
     },
     "target_splits_per_chunk": 20  // Optional, default is fine
   }
   ```

### ‚úÖ Search

**Your Implementation:**
```rust
POST /api/chunk/search
Headers:
  - Authorization: Bearer {API_KEY}
  - TR-Dataset: {DATASET_ID}
Body: {
  "query": "How to maintain pump seals?",
  "page_size": 3,
  "score_threshold": 0.25
}
```

**Verdict:** ‚úÖ **CORRECT** but missing required field

**Required Addition:**
```json
{
  "query": "How to maintain pump seals?",
  "search_type": "hybrid",  // REQUIRED field
  "page": 1,
  "page_size": 3,
  "score_threshold": 0.25
}
```

**Search Type Options:**
- `"semantic"`: Dense vector similarity (best for conceptual queries)
- `"fulltext"`: SPLADE sparse vector (best for exact keywords)
- `"hybrid"`: **Recommended** - combines both with re-ranking
- `"bm25"`: Traditional keyword search

**Recommendation:** Use `"hybrid"` for best results.

### ‚úÖ Response Parsing

### ‚úÖ RAG Completion (LLM Answers)

**New Implementation:**
```rust
POST /api/chunk/generate
Headers:
  - Authorization: Bearer {API_KEY}
  - TR-Dataset: {DATASET_ID}
  - X-API-Version: v2
Body: {
  "query": "How to maintain pump seals?",
  "search_type": "hybrid",
  "page_size": 5,
  "score_threshold": 0.25,
  "llm_options": {
    "model": "gpt-3.5-turbo",
    "temperature": 0.1,
    "max_tokens": 1000,
    "system_message": "You are an expert maintenance technician..."
  }
}
```

**Verdict:** ‚úÖ **NEW FUNCTIONALITY ADDED**

This provides the same user experience as AnythingLLM - ask a question, get a formatted answer.

**Response Format:**
```json
{
  "completion": "To maintain pump seals, follow these steps...",
  "chunks": [
    {
      "chunk": { "chunk_html": "...", "metadata": {...} },
      "score": 0.87
    }
  ]
}
```

**Benefits:**
- Complete answers ready for users
- Sources included for verification
- Customizable LLM behavior
- Consistent with AnythingLLM experience

**Expected Response Structure:**

The response structure depends on API version:

**API v1** (older organizations):
```json
{
  "score_chunks": [
    {
      "chunk": { ... },
      "score": 0.87
    }
  ]
}
```

**API v2** (new organizations, recommended):
```json
{
  "chunks": [
    {
      "chunk": { ... },
      "score": 0.87
    }
  ]
}
```

**Recommendation:** Add `X-API-Version: v2` header to ensure consistent response format.

**Your Rust Implementation Should:**
```rust
#[derive(Deserialize)]
struct SearchResponse {
    chunks: Vec<ScoredChunk>,  // v2 format
}

#[derive(Deserialize)]
struct ScoredChunk {
    chunk: ChunkMetadata,
    score: f64,
}

#[derive(Deserialize)]
struct ChunkMetadata {
    id: String,
    chunk_html: String,
    metadata: Option<serde_json::Value>,
    tag_set: Option<Vec<String>>,
    // ... other fields
}
```

## Configuration Guide

### ‚úÖ Your config.toml Structure

**Your Configuration:**
```toml
[rag]
enabled = true
provider = "trieve"

trieve_api_endpoint = "http://localhost:8090/api"
trieve_api_key = "..."
trieve_organization_id = "..."

relevance_threshold = 0.25
max_results = 3
timeout_seconds = 30
```

**Verdict:** ‚úÖ **CORRECT**

### Recommended Configuration

**For Local Development:**
```toml
[rag]
enabled = true
provider = "trieve"

# Local Trieve instance
trieve_api_endpoint = "http://localhost:8090/api"
trieve_api_key = "tr_YOUR_API_KEY_FROM_DASHBOARD"
trieve_organization_id = "YOUR_ORG_UUID_FROM_DASHBOARD"

# Search settings
relevance_threshold = 0.25  # Good default
max_results = 3             # Adjust based on context window
timeout_seconds = 30        # Increase if uploading large files

# Optional: API version
trieve_api_version = "v2"   # Recommended for consistent responses
```

**For Production (Cloud Trieve):**
```toml
[rag]
enabled = true
provider = "trieve"

# Cloud Trieve
trieve_api_endpoint = "https://api.trieve.ai/api"
trieve_api_key = "${TRIEVE_API_KEY}"  # From environment
trieve_organization_id = "${TRIEVE_ORG_ID}"

relevance_threshold = 0.3   # Slightly higher for production
max_results = 5
timeout_seconds = 60
```

### Environment Variables (Recommended)

For security, use environment variables:

```bash
# .env
TRIEVE_API_KEY=tr_your_api_key_here
TRIEVE_ORG_ID=00000000-0000-0000-0000-000000000000
```

```toml
# config.toml
[rag]
trieve_api_key = "${TRIEVE_API_KEY}"
trieve_organization_id = "${TRIEVE_ORG_ID}"
```

## Performance Considerations

### Chunking Strategies

**Trieve Auto-Chunking:**
- Default: ~512 tokens per chunk
- Configurable via `target_splits_per_chunk`

**Recommended for Technical Manuals:**
```json
{
  "target_splits_per_chunk": 20,
  "use_pdf2md_ocr": false  // Use Tika for speed
}
```

**Chunking Quality Trade-offs:**

| Strategy | Speed | Quality | Cost | Best For |
|----------|-------|---------|------|----------|
| Tika (default) | Fast | Good | Low | Most PDFs, text-heavy manuals |
| Vision LLM (`use_pdf2md_ocr: true`) | Slow | Excellent | High | Complex layouts, tables, diagrams |

**Recommendation:** Start with Tika. Use vision LLM only for complex manuals with diagrams.

### Index Optimization

**Enable All Search Modes:**
```json
{
  "FULLTEXT_ENABLED": true,
  "SEMANTIC_ENABLED": true,
  "BM25_ENABLED": true
}
```

**Benefits:**
- Fulltext: Fast keyword matching
- Semantic: Conceptual understanding
- BM25: Traditional relevance ranking
- Hybrid: Best of all worlds

**Trade-off:**
- Slightly more storage and indexing time
- Significantly better search quality

**Recommendation:** ‚úì Enable all modes for production.

### Query Performance

**Optimization Tips:**

1. **Use score_threshold**: Filters results early, reduces processing
   ```rust
   score_threshold: Some(0.25)  // Filter low-quality results
   ```

2. **Limit page_size**: Only retrieve what you need
   ```rust
   page_size: 3  // Perfect for RAG context
   ```

3. **Use slim_chunks**: Exclude content when only checking existence
   ```rust
   slim_chunks: true  // Returns metadata only, ~40% faster
   ```

4. **Filter by tags**: Tags use HNSW indices (very fast)
   ```rust
   filters: {
     must: [{ field: "tag_set", match_any: ["device:pump-001"] }]
   }
   ```

5. **Avoid metadata filtering**: Slower than tags
   ```rust
   // Prefer this:
   tag_set: ["device:pump-001"]

   // Over this:
   metadata: { device_id: "pump-001" }
   ```

### Embedding Model Selection

**Default: OpenAI text-embedding-3-small**
- Dimensions: 1536
- Speed: Fast (~100ms per request)
- Quality: Excellent for most use cases
- Cost: $0.02 per 1M tokens

**Alternative: OpenAI text-embedding-3-large**
- Dimensions: 3072
- Speed: Slower (~150ms)
- Quality: Best in class
- Cost: $0.13 per 1M tokens

**For Technical Manuals:** `text-embedding-3-small` is sufficient ‚úì

### Async File Processing

**Important:** File upload API returns immediately, but chunk creation is asynchronous.

**Your Implementation Should Handle:**

```rust
// 1. Upload returns file_id immediately
let file_response = upload_file(pdf).await?;

// 2. Chunks are created in background (5-60 seconds typically)
// Don't query immediately!

// 3. Option A: Wait before querying
tokio::time::sleep(Duration::from_secs(30)).await;

// 4. Option B: Poll for completion
loop {
    let file = get_file(file_response.id).await?;
    if file.chunks_created > 0 {
        break;
    }
    tokio::time::sleep(Duration::from_secs(5)).await;
}

// 5. Option C: Use webhooks (advanced)
// Configure webhook URL to be notified when processing completes
```

**Recommendation:** For production, implement Option B (polling) or C (webhooks).

## Scaling Recommendations

### Datasets per Organization

**Your Model:** One dataset per device

**Trieve Limits:**
- Self-hosted with `UNLIMITED=true`: No hard limit
- Cloud Free: ~10 datasets
- Cloud Pro: ~100 datasets
- Cloud Enterprise: Unlimited

**Recommendation for Production:**

If you have many devices (100+), consider:

**Option 1: One dataset per device** (current approach)
- ‚úÖ Perfect isolation
- ‚úÖ Easy to manage permissions
- ‚ùå Scales poorly with 1000+ devices

**Option 2: One dataset per organization, tag by device**
```json
{
  "tag_set": ["device:pump-001", "device:compressor-002"],
  "metadata": { "device_id": "pump-001" }
}
```

Then filter searches:
```json
{
  "query": "maintenance",
  "filters": {
    "must": [{ "field": "tag_set", "match_any": ["device:pump-001"] }]
  }
}
```

- ‚úÖ Scales to unlimited devices
- ‚úÖ Lower dataset management overhead
- ‚ùå All org data in one dataset
- ‚ùå Slightly more complex queries

**Recommendation:**
- **< 50 devices**: One dataset per device ‚úì
- **50-500 devices**: One dataset per device or per org (depends on isolation needs)
- **500+ devices**: One dataset per org, filter by tags

### Chunks per Dataset

**Trieve Performance:**
- Up to 1M chunks per dataset: Excellent performance
- 1M-10M chunks: Good performance
- 10M+ chunks: Consider partitioning

**For Equipment Manuals:**
- Average manual: 50-200 pages
- Chunks per page: ~2-5
- **Total chunks per manual: 100-1000**

**Recommendation:**
- One dataset can handle 100+ manuals (10,000-100,000 chunks)
- For most use cases, one dataset per device is fine

### Concurrent Operations

**File Upload Concurrency:**
```rust
use futures::stream::{self, StreamExt};

// Upload 5 files in parallel
stream::iter(files)
    .map(|file| upload_file(file))
    .buffer_unordered(5)
    .collect::<Vec<_>>()
    .await;
```

**Recommendation:** Limit to 5-10 concurrent uploads to avoid overwhelming the server.

**Search Concurrency:**
- No hard limits for self-hosted
- Cloud API: Respect rate limits

### Storage Considerations

**Trieve Storage:**
- PDF files: Stored in S3 (MinIO locally)
- Chunks: Stored in PostgreSQL
- Vectors: Stored in Qdrant

**Estimations (per 100-page manual):**
- Original PDF: ~5-10 MB
- Chunk text (PostgreSQL): ~500 KB
- Vectors (Qdrant): ~2-3 MB (for 1536-dim embeddings)
- **Total: ~8-14 MB per manual**

**For 1000 manuals:** ~8-14 GB total storage

**Recommendation:** Plan for 20-30 MB per manual including overhead.

## Comparison with AnythingLLM

| Feature | Trieve | AnythingLLM |
|---------|--------|-------------|
| **Architecture** | Cloud-native, microservices | Monolithic, all-in-one |
| **Vector DB** | Qdrant (dedicated) | ChromaDB/LanceDB/Pinecone |
| **Search Types** | Semantic, Fulltext, BM25, Hybrid | Semantic only |
| **Chunking** | Automatic, configurable | Manual or basic auto |
| **Multi-tenancy** | Native (orgs + datasets) | Limited (workspaces) |
| **API Quality** | RESTful, well-documented | REST, less documented |
| **File Formats** | PDF, DOCX, TXT, HTML, etc. | PDF, TXT, DOCX |
| **OCR** | Optional (vision LLM) | No |
| **Scaling** | Excellent (distributed) | Limited (single instance) |
| **Self-Hosted** | Docker Compose or K8s | Docker |
| **Performance** | Excellent (optimized indices) | Good |
| **RAG Features** | Built-in RAG routes | Basic |
| **Cost** | Free (self-host) or cloud tiers | Free (self-host) or cloud |

### When to Use Trieve

‚úÖ **Best for:**
- Multi-tenant applications (your use case ‚úì)
- Large-scale deployments (100+ devices)
- Need hybrid search (semantic + keyword)
- Production RAG systems
- Advanced filtering and tagging

### When to Use AnythingLLM

‚úÖ **Best for:**
- Simple, single-user RAG
- Quick prototypes
- All-in-one simplicity
- Non-technical users (good UI)

### Migration Considerations

If you need to switch providers:

**From AnythingLLM ‚Üí Trieve:**
1. Export documents from AnythingLLM
2. Create Trieve datasets
3. Re-upload documents (Trieve will re-chunk and re-embed)
4. Update configuration
5. Test search results

**From Trieve ‚Üí AnythingLLM:**
1. Export files via Trieve API
2. Import into AnythingLLM workspaces
3. Re-chunk and re-embed
4. Update configuration

**Note:** No direct migration path exists. Both require re-processing documents.

## Testing Strategy

### Unit Tests

**Test Your Trieve Client:**

```rust
#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_create_dataset() {
        let client = TrieveClient::new(config);
        let dataset = client.create_dataset("test-device-001").await.unwrap();
        assert!(dataset.id.len() > 0);
    }

    #[tokio::test]
    async fn test_upload_file() {
        let client = TrieveClient::new(config);
        let pdf_data = include_bytes!("test-manual.pdf");
        let result = client.upload_document(
            "test-dataset-id",
            "test-manual.pdf",
            pdf_data
        ).await;
        assert!(result.is_ok());
    }

    #[tokio::test]
    async fn test_search() {
        let client = TrieveClient::new(config);
        let results = client.query(
            "test-dataset-id",
            "test query",
            3
        ).await.unwrap();
        assert!(results.len() <= 3);
    }
}
```

### Integration Tests

**Test Against Local Trieve:**

```rust
#[cfg(test)]
mod integration_tests {
    #[tokio::test]
    #[ignore]  // Run with: cargo test -- --ignored
    async fn test_full_workflow() {
        let client = TrieveClient::new(test_config());

        // 1. Create dataset
        let dataset = client.create_dataset("integration-test-001").await.unwrap();

        // 2. Upload test PDF
        let pdf = include_bytes!("fixtures/test-manual.pdf");
        let file = client.upload_document(
            &dataset.id,
            "test-manual.pdf",
            pdf
        ).await.unwrap();

        // 3. Wait for processing
        tokio::time::sleep(Duration::from_secs(30)).await;

        // 4. Search
        let results = client.query(
            &dataset.id,
            "maintenance procedure",
            3
        ).await.unwrap();

        assert!(results.len() > 0);
        assert!(results[0].score >= 0.25);

        // 5. Cleanup
        client.delete_dataset(&dataset.id).await.unwrap();
    }
}
```

### Load Tests

**Test Concurrent Operations:**

```rust
#[tokio::test]
#[ignore]
async fn test_concurrent_searches() {
    let client = Arc::new(TrieveClient::new(test_config()));
    let dataset_id = "test-dataset";

    let handles: Vec<_> = (0..100).map(|i| {
        let client = Arc::clone(&client);
        tokio::spawn(async move {
            client.query(dataset_id, &format!("query {}", i), 3).await
        })
    }).collect();

    let results = futures::future::join_all(handles).await;
    let successes = results.iter().filter(|r| r.is_ok()).count();

    assert!(successes >= 95); // At least 95% success rate
}
```

### Manual Testing Checklist

- [ ] Can create organization in dashboard
- [ ] Can create API key with correct permissions
- [ ] Can create dataset via API
- [ ] Can upload small PDF (<1MB)
- [ ] Can upload large PDF (>10MB)
- [ ] Chunks are created automatically
- [ ] Can search and get results
- [ ] Score threshold filtering works
- [ ] Can query multiple datasets independently
- [ ] Can delete documents
- [ ] Can delete datasets
- [ ] Error handling works correctly
- [ ] Timeouts are handled properly

## Common Issues and Solutions

### Issue: Dataset Creation Returns 409 Conflict

**Cause:** Dataset with same `tracking_id` already exists

**Solution:** Implement get-or-create pattern:
```rust
match get_dataset_by_tracking_id(device_id).await {
    Ok(dataset) => Ok(dataset),
    Err(_) => create_dataset(device_id).await,
}
```

### Issue: Search Returns Empty Results

**Possible Causes:**
1. Chunks not yet created (async processing)
2. Score threshold too high
3. Wrong dataset ID
4. Query too specific

**Solutions:**
1. Wait 30-60 seconds after upload
2. Lower threshold to 0.1 for testing
3. Verify dataset ID in logs
4. Try broader query

### Issue: File Upload Times Out

**Cause:** Large PDF or slow network

**Solution:**
- Increase `timeout_seconds` in config
- Check file size (should be < 50MB typically)
- Verify network connectivity
- Check Trieve server logs

### Issue: Inconsistent Search Results

**Cause:** API version mismatch (v1 vs v2 response format)

**Solution:** Add header:
```rust
headers.insert("X-API-Version", "v2");
```

## Performance Benchmarks

### Expected Performance (Local Trieve)

| Operation | Typical Time | Notes |
|-----------|--------------|-------|
| Create dataset | 100-300ms | One-time per device |
| Upload 5MB PDF | 500ms-2s | Network dependent |
| Chunk creation | 10-60s | Async, depends on PDF size |
| Semantic search | 200-500ms | Depends on dataset size |
| Hybrid search | 300-700ms | Includes re-ranking |

### Optimization Tips

1. **Reuse datasets**: Don't recreate on every request
2. **Cache dataset IDs**: Store mapping of device_id ‚Üí dataset_id
3. **Batch uploads**: Upload multiple files concurrently
4. **Use connection pooling**: Reuse HTTP connections
5. **Monitor slow queries**: Log searches >1s for investigation

## Conclusion

Your Trieve integration is well-designed and follows best practices. Key recommendations:

1. ‚úÖ **API Usage**: Your implementation is correct with minor adjustments needed
2. ‚úÖ **Data Model**: Org + device isolation is excellent
3. ‚úÖ **Configuration**: Good defaults, consider adding API version
4. üîß **Add `search_type`**: Required field for search API
5. üîß **Remove `create_chunks`**: Not a valid field
6. üîß **Add `tracking_id`**: For easier dataset lookup
7. üîß **Handle API v2**: Add version header for consistent responses

With these small adjustments, your integration will work perfectly with Trieve!
